{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Big Picture of Bayesian Deep Learning\n",
    "\n",
    "\n",
    "베이지안적 딥러닝이란 과연 무엇인가? 이 질문을 바꿔 말하면, 딥러닝에 베이지안 기법을 어떻게 적용할 수 있을 것인가로 다시 물어볼 수 있을 것이다.\n",
    "딥러닝(머신러닝의 다른 지도학습도 그렇지만)은 정답이 있는 훈련 데이터 $ D=((x_{1},y_{1}), (x_{2},y_{2}), ..., (x_{n},y_{n}))$ 를 학습하여 모델을 만든 후, 정답이 없는 테스트 데이터의 정확한 답을 제시하는 것을 목적으로 한다. 정답률의 최대는 오차의 최소를 의미하며, 이를 수식으로 표현하면 다음과 같다.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ Obj = E\\mathcal ({L}(y, f{(x)})\\tag{1}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "위 식을 풀기 위해서 $f(x)$ 를 통한 예측 값을 알아야 하며, 우리는 이것을 $f(x)$ 와 대응되는 $p(y|x)$ 로 표현할 수 있다. 그런데 파라미터 또는 잠재변수 벡터로 이루어진 $\\theta$ 의 공간에서 $p_{\\theta}(x,y) = p(x,y|\\theta)$ 이므로 주어진 데이터셋 $D$에서 $p(y|x)$ 도 다음과 같이 표현이 가능하다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ \\mathcal p(y|x,D) = \\int{p(y|x,D,\\theta)p(\\theta|x,D)d\\theta} \\tag{2}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "여기서 $\\theta$ 는 우리가 추정해야 하는 파라미터 벡터이다. RHS의 항을 살펴보면, $p(y|x,D,\\theta)$는 주어진 데이터와 $\\theta$값을 알고 있으므로 어렵지 않게 계산이 가능하다. 문제는 $p(\\theta|x,D)$ 와 $\\theta$에 대한 적분($\\int$) 계산이다. 바로 이 두 개의 이슈가 베이지안의 시작이며, 앞으로 우리가 다루는 대부분의 것들이 이 두 개를 계산하기 위한 것임을 기억해야 한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "먼저 $p(\\theta|x,D)$ 를 살펴보자. 익숙한 표현 아닌가? 바로 우리가 베이지안을 접하면 가장 먼저 보는 베이즈 정리(Bayes' Theorem)의 사후분포(Posterior Distribution)의 형태이다. 이것의 계산 방법으로는 다음의 4가지 방법이 있고 이 중 1.Exact Inference는 강한 가정에 기반하고 있어 필자가 생각하기에 잘 안 쓰이는 방법으로 판단하여 이를 제외한 세 가지 방법(2번~4번)에 대해 집중적으로 다뤄볼 예정이다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Exact Inference : Multivariate Gaussian, Conjugate Priors, Graphical Models\n",
    "2. Point Estimate of $\\theta$ : MLE, MAP, Optimization, EM\n",
    "3. Deterministic Approximation : Laplace Approximation, Variational Methods, Expectation Propagation\n",
    "4. Stochastic Approximation : MCMC(Gibbs, MH), Importance Sampling (Particle Filtering)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "오늘 우리는 베이지안 딥러닝의 접근 방법에 대해서 개괄적으로 알아봤다. 요약하면, 우리의 목표는 기대되는 손실함수 값을 구하는 것이지만, 실질적으로 사후분포 $p(\\theta|x,D)$ 와 $\\theta$ 에 대한 적분($\\int$) 을 계산하는 것이다. 따라서 우리는 다음 포스팅부터 이 두 가지 계산을 어떻게 할 것인지에 대해 하나하나씩 공부해 갈 것이다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
